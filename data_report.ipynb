{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e4bf37b-85bc-445e-b2b9-14976010a4b0",
   "metadata": {},
   "source": [
    "#                                    Project Data Report: PREDICTING H1N1 VACCINE UPTAKE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea44be1-6dfb-44a6-beb6-81805cbfa1e0",
   "metadata": {},
   "source": [
    "## 1.0 OVERVIEW\n",
    "This study uses data from the National 2009 H1N1 Flu Survey (NHFS) to examine vaccination uptake during the 2009 H1N1 influenza pandemic. Developing predictive models that identify the variables affecting vaccination choices for the seasonal flu and H1N1 vaccines is the aim. Our goal is to improve vaccination rates and stop future outbreaks by using machine learning techniques to provide insights for public health strategies.\n",
    "\n",
    "The dataset comprises 26,707 respondents  that cover perceptions, health behaviors, and demographics. These are the main findings.\n",
    "A low overall uptake rate was found by exploratory analysis (21% for H1N1 and 36% for seasonal flu), with correlations found to variables such as health concerns and physician recommendations.\n",
    "Features like \"doctor_recc_h1n1\" were highlighted as powerful predictors by the models (logistic regression, decision trees, and random forests), which achieved a respectable accuracy (~85% for H1N1 and ~76% for seasonal).\n",
    "Recommendations include educating people about vaccine hesitancy and launching targeted campaigns for high-risk populations.\n",
    "\n",
    "The dataset's age (2009), which might not accurately reflect current behaviors, and possible survey bias are among its limitations. New data or sophisticated models like neural networks may be used in future research.\n",
    "\n",
    "This study illustrates how data-driven strategies can improve public health readiness and possibly minimize the effects of infectious diseases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b545437-228e-4b91-a5b2-cc90fe4d8993",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 1.1 Introduction\n",
    "\n",
    "# Business Problem\n",
    "A vital component of public health, vaccinations save lives and stop the spread of infectious diseases. Vaccines were created and made available to lessen the effects of the 2009 H1N1 (\"swine flu\") pandemic, which is estimated to have killed between 151,000 and 575,000 people worldwide in its first year. But because of things like misinformation, hesitancy, and access problems, uptake was poor.\n",
    "\n",
    "**What factors influence vaccination uptake for seasonal flu and H1N1 and how can we predict it to inform targeted interventions? **This project answers this question.**  Through the analysis of NHFS survey data, we create predictive models to pinpoint at-risk populations and suggest tactics for organizations, legislators, and medical professionals to increase vaccination rates. For future pandemics, where quick, widespread adoption can lower mortality and financial expenses, this is essential.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbac646e-75dd-4565-b663-f3eb4713615e",
   "metadata": {},
   "source": [
    "\n",
    "# 1.2 Objectives\n",
    "The goal of this research is to create a data-driven plan for expanding H1N1 vaccination through individualized and focused public health initiatives.\n",
    "\n",
    "Specific Objectives\n",
    "\n",
    "- Develop a classification model that predicts a person's likelihood of receiving the H1N1 vaccine.\n",
    "\n",
    "- Determine At-Risk Populations: Divide the population into groups that are most likely to not receive vaccinations.\n",
    "\n",
    "- Recognize Key Drivers: Determine which attitudes, actions, demographics, and access to care have the greatest impact on vaccine acceptance and hesitancy.\n",
    "\n",
    "- Compare Models: Assess various machine learning methods to identify the best one for forecasting vaccination uptake."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55145a2c-b3e2-4694-9453-a0e4007f2d76",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 1.3 Scope and Limitations\n",
    "- Scope: Use survey data to focus on binary classification for H1N1.\n",
    "- Restrictions: The data is U.S.-centric (may not generalize globally), self-reported (possible bias), and from 2009. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8661065-cb0d-4cc1-89ed-bdc6c5474ec9",
   "metadata": {},
   "source": [
    "\n",
    "# 1.4 Stakeholder Analysis\n",
    "Stakeholders consist of:\n",
    "- **Public Health Officials and Governments**: Utilize models to plan campaigns and distribute resources (e.g., focus on low-uptake areas).\n",
    "**Healthcare Providers**: Determine patient profiles for tailored advice (e.g., give priority to high-risk groups such as individuals with chronic conditions).\n",
    "- **NGOs and policymakers**: Reduce hesitancy by informing policies on vaccine access and education.\n",
    "The general public indirectly benefits from better vaccination practices, which result in herd immunity.\n",
    "\n",
    "\n",
    "Stakeholder prioritization: For immediate impact, concentrate on officials and providers, as models can direct interventions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2023a6d-3b0b-4793-a091-fbff1eb93c1b",
   "metadata": {},
   "source": [
    "## 2 Data Understanding\n",
    "# 2.1 Data Sources\n",
    "Source: CDC's National 2009 H1N1 Flu Survey (NHFS)\n",
    "\n",
    "Records: 26,707 U.S. citizen survey responses.\n",
    "\n",
    "h1n1_vaccine is the target variable (1 = vaccinated, 0 = not vaccinated).\n",
    "\n",
    "Qualities:\n",
    "\n",
    "Opinions and Knowledge: perceived efficacy, knowledge, and concern.\n",
    "\n",
    "Behaviors include wearing masks, washing your hands, and staying away from crowds.\n",
    "\n",
    "Age, income, race, insurance, and region are examples of demographics.\n",
    "\n",
    "External influences include medical advice and employment in the healthcare industry.\n",
    "\n",
    "Relevance: Offers rich predictors for evaluating vaccination choices, locating vulnerable populations, and guiding public health initiatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0583ac7a-b862-4654-b09f-ecedcc9c6dbf",
   "metadata": {},
   "source": [
    "## 2.2 Data Preparation and Cleaning\n",
    "# Handling Missing Values\n",
    "- Determined which columns (such as `health_insurance` and `employment_industry`) had more than 40% missing.\n",
    "- Imputation: Used median for numerical and mode for categorical .\n",
    "- dropped employment_industry and employment_occupation columns which were missing over 13,000 entries around 50% of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eccebe5-7662-4ca4-99f6-9f4730760e7c",
   "metadata": {},
   "source": [
    "# 2.3 Encoding Categorical Variables\n",
    "Using stratified sampling, we first divided the dataset into training (80%) and testing (20%) sets, making sure that the proportion of vaccinated versus non-vaccinated people in each set was balanced. This was crucial since our target variable (h1n1_vaccine) is extremely imbalanced, and if stratification isn't used, one set may have too few vaccinated cases, which could result in inaccurate training or assessment.\n",
    "\n",
    "- We fixed missing values and made sure the formatting was consistent for preprocessing:\n",
    "\n",
    "- Numerical columns: StandardScaler was used to scale features so that all values fall within a similar range, and the median was used to fill in missing values.\n",
    "\n",
    "- Categorical columns: We used One-Hot Encoding to turn categories into binary (0/1) columns and filled in missing values with the most common category (mode).\n",
    "\n",
    "We were able to apply preprocessing consistently throughout model training and testing by combining these steps into a single ColumnTransformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bceb8b-9d6a-4fd0-aa8d-c569d6c6a6f6",
   "metadata": {},
   "source": [
    "# 2.3 Encoding Categorical Variables\n",
    "# EDA after data preparation\n",
    "Using a heatmap, we looked at feature correlations. The findings indicated that there were no pairs of variables with extremely high collinearity (|r| > 0.8) and that the majority of features had low to moderate correlations.\n",
    "\n",
    "This suggests that multicollinearity is not an issue for this dataset. As a result, we can keep every feature for modeling without deleting or combining variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abca4e20-7ed8-48f2-b499-2742fd133ead",
   "metadata": {},
   "source": [
    "# 2.4 Class Imbalance Check\n",
    "\n",
    "- There is a significant imbalance in the target variable (H1N1 vaccine) bar chart:\n",
    "\n",
    "- The vast majority of respondents (class 0) did not receive a vaccination.\n",
    "\n",
    "- Only a smaller percentage (class 1) were vaccinated.\n",
    "\n",
    "- Because of this imbalance, a model could achieve high accuracy by primarily predicting the majority class, making accuracy by itself deceptive.\n",
    "\n",
    "We will evaluate this using metrics like F1-score, AUC-ROC, Precision, and Recall. To address this imbalance during modeling, we might also take into account class weighting or resampling strategies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624f3ad1-9d71-4ba0-bbeb-15a796d0b7be",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Data Preparation Conclusion\n",
    "\n",
    "- We have finished all the procedures required to get the dataset ready for modeling:\n",
    "\n",
    "- developed fresh, more educational features (prevention index, opinion scores, etc.).\n",
    "\n",
    "- Features that could lead to data leakage, duplicate columns, and dropped IDs.\n",
    "\n",
    "- To maintain class balance, divide the data into training (80%) and testing (20%) sets using stratification.\n",
    "\n",
    "- One-hot encoding for categorical features, scaling for numerical features, and imputation for missing values are examples of applied preprocessing.\n",
    "\n",
    "- confirmed that multicollinearity would not be caused by any highly correlated features.\n",
    "\n",
    "- verified that the h1n1 vaccine target variable is unbalanced and needs extra attention when being evaluated.\n",
    "\n",
    "At this point, the dataset is completely numeric, clean, and prepared for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800b7c88-e01b-4917-bfec-6c4c95178feb",
   "metadata": {},
   "source": [
    "## 4. Modeling & Evaluation\n",
    "\n",
    "- We will use an iterative approach to our modeling strategy:\n",
    "\n",
    "- Start with a baseline model that is easy to understand.\n",
    "\n",
    "- Test increasingly intricate models one after the other.\n",
    "\n",
    "- To enhance performance, use hyperparameter tuning.\n",
    "\n",
    "- To guarantee dependability and prevent overfitting, cross-validation will be used to validate every model.\n",
    "\n",
    "- Recall for the positive class (vaccinated = 1) will be our main evaluation metric. False negatives are more expensive than false positives in this  public health setting. It is more dangerous to miss someone who would genuinely get vaccinated (false negative) than to make a false positive prediction.\n",
    "\n",
    "- This guarantees that the finished model is accurate and in line with the practical objective of identifying the greatest number of possible vaccine recipients for focused interventions.\n",
    "\n",
    "\n",
    "# 4.1 Cross-Validation Results\n",
    "\n",
    "- 5-fold cross-validation was used to assess the baseline Logistic Regression model, with recall serving as the main metric:\n",
    "\n",
    "- Scores for CV Recall: [0.66, 0.71, 0.68, 0.68, 0.68]\n",
    "\n",
    "- Mean CV Recall: 0.68\n",
    "\n",
    "- 0.017 is the CV Recall Standard.\n",
    "\n",
    "This indicates that, with minimal variation across folds, the model accurately identifies roughly two-thirds of vaccinated individuals. Although this is a good place to start, it also shows that about one in three vaccinated people are overlooked, underscoring the need for a more robust model to reduce false negatives.\n",
    "\n",
    "# 4.2 Training vs. Test Evaluation\n",
    "\n",
    "The model was then fitted on the entire training set and evaluated on both training and test sets:\n",
    "\n",
    "- Training Recall (vaccinated=1): 0.69\n",
    "\n",
    "- Test Recall (vaccinated=1): 0.68\n",
    "\n",
    "- Training Accuracy: 0.77\n",
    "\n",
    "- Test Accuracy: 0.76\n",
    "\n",
    "The close similarity between training and test performance suggests the model is not overfitting and generalizes well to unseen data. This stability is likely due to the use of class weighting and the simplicity of logistic regression.\n",
    "\n",
    "# 4.3 Model Interpretation\n",
    "\n",
    "Performance: 68% of vaccine recipients are identified by the model, which has a test recall of 0.68. For class 1, however, its precision is comparatively low (0.46), indicating that almost half of the positive predictions are wrong. Given that only about 21% of respondents were vaccinated, this imbalance is to be expected.\n",
    "\n",
    "Overfitting Check: Generalization is confirmed when there is little variation between training and test results.\n",
    "\n",
    "Implications for Business:\n",
    "\n",
    "Strength: By capturing the majority of the positive class, the model offers a trustworthy baseline for identifying vaccinated individuals.\n",
    "\n",
    "Limitation: Because of the low precision, resources might be used to target people who are unlikely to receive vaccinations.\n",
    "\n",
    "Acceptable Trade-off: False negatives are more expensive than false positives in the context of public health. The effectiveness of the intervention is compromised when someone who would be vaccinated is missed, and the cost is only increased when more people are targeted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfbe7c0-e3a8-462f-a912-20fcd6e8c3d2",
   "metadata": {},
   "source": [
    "# 4.4 Random Forest\n",
    "Random Forest – Model Evaluation\n",
    "Performance Interpretation\n",
    "\n",
    "- Training Recall (vaccinated=1): 0.99\n",
    "\n",
    "- Test Recall (vaccinated=1): 0.36\n",
    "\n",
    "- Test Accuracy: 0.82\n",
    "\n",
    "- The Random Forest model shows severe overfitting. While it almost perfectly identifies vaccinated individuals in training, on the test set it only captures 1 in 3 cases. Accuracy is misleading here, as it mainly reflects strong performance on the majority class (not vaccinated).\n",
    "\n",
    "- Overfitting Analysis\n",
    "\n",
    "- Recall (train vs. test): 0.99 → 0.36\n",
    "\n",
    "- Accuracy (train vs. test): 0.99 → 0.82\n",
    "\n",
    "- This large performance gap confirms that the model memorized training data but fails to generalize.\n",
    "\n",
    "- Business Implications\n",
    "\n",
    "A recall of 0.36 for vaccinated individuals means the model misses nearly two-thirds of true positives, making it unsuitable for public health objectives. While its precision is relatively higher (0.62), the low recall undermines its usefulness for identifying at-risk populations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47601b9-66b8-439e-92a2-db72eef771f8",
   "metadata": {},
   "source": [
    "# 4.5 Logistic Regression with Hyperparameter Tuning\n",
    "- GridSearchCV hyperparameter tuning of logistic regression did not significantly enhance performance over the baseline. For vaccinated individuals, accuracy slightly declined (0.78 vs. 0.76), precision remained steady (0.46 vs. 0.45), and recall remained nearly unchanged (0.68 baseline vs. 0.67 tuned). This suggests that tuning did not improve recall because the baseline model was already nearly ideal.\n",
    "\n",
    "- Modifying the classification threshold had a greater effect. Recall significantly improved from 0.68 to 0.77 when the threshold was lowered from 0.5 to 0.4, enabling the model to accurately identify 77% of vaccinated people. The anticipated trade-off of adding more false positives was reflected in the precision dropping to 0.38.\n",
    "\n",
    "- With nearly identical training and test performance (recall: 0.78 vs. 0.77, accuracy: 0.73 vs. 0.72), the model is still demonstrating strong generalization. This demonstrates that recall was enhanced by the threshold adjustment without causing overfitting.\n",
    "\n",
    "- This change is very helpful from a business point of view. More than three-quarters of the vaccinated population can now be identified by the model, greatly increasing the coverage for public health targeting. This is a reasonable price to ensure that the majority of actual vaccine recipients are enrolled, even though some inefficiency is introduced (6 out of 10 flagged individuals will not vaccinate)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6f5196-5a96-4228-9d67-016f7127fc00",
   "metadata": {},
   "source": [
    "# 5. Final Model Evaluation & Conclusion\n",
    "\n",
    "Implications\n",
    "- 77% of vaccinated people can be identified using the optimized logistic regression model, which makes it useful for focusing public health messaging. It can be used by agencies to create customized campaigns and allocate resources effectively. Outreach efforts can focus on people who are unlikely to get vaccinated.\n",
    "\n",
    "Restrictions\n",
    "- Results may not be generalizable because the model is based on survey data from a particular time and place. Doctor recommendations are one example of a feature that may not always be available. Outreach must reach more people than is necessary due to a high false positive rate of 71%.\n",
    "\n",
    "Suggestions\n",
    "- Target audiences with high doctor recommendations and opinion scores. Gather data on vaccine attitudes in real time. Before scaling, test the model regionally.\n",
    "\n",
    "Next Actions\n",
    "- To increase accuracy without overfitting, test advanced models like XGBoost and investigate new characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de870934-f56d-4c12-aa6f-dec58e7b49d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
